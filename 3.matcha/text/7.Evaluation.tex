\section{Evaluation}
%This section presents an evaluation of our system and compares it with five state-of-the-art systems for different subgraph matching tasks. 

\subsection{Experimental Setup}
\noindent
\textbf{\textit{Platform.}} Our experiments are conducted on a dual-socket machine with Intel Xeon Gold 6226R 2.9GHz CPUs (32 cores in total), 512GB RAM, and an Nvidia A100 GPU. 
The generated CPU code was compiled using GCC 9.4.0, and the generated GPU code was compiled using NVCC 11.2. 



\noindent
\textbf{\textit{Subgraph Matching Tasks.}} We evaluate the performance of four representative subgraph matching tasks: $k$-motif counting ($k$-MC), subgraph listing (SL), $k$-clique counting ($k$-CL), and temporal subgraph listing (TSL). A more detailed description of the tasks can be found in Section~\ref{sec:background_problem}. 

\noindent
\textbf{\textit{Datasets.}}
Table~\ref{tab:datasets} lists the data graphs used in our experiments. 
Six static graphs are used for $k$-MC, SL, and $k$-CL, and three temporal graphs are used for TSL. 
These graphs are commonly used to evaluate subgraph matching systems in previous work~\cite{chen2018g, chen2022decomine}. 
For labeled SL, we randomly assign five labels to the vertices in the graphs. 
\begin{table}[H]
  \centering
  \footnotesize
  \caption{Graph datasets.}
    \begin{tabular}{c|c|c|c}
     \textbf{Graph} & \textbf{\# nodes} & \textbf{\# edges} & \textbf{Max degree}\\
    \hline\hline
    MiCo (mc)   & 96K   & 1.1M  & 1359 \\
    DBLP  (db)    & 317K  & 1.0M  & 343 \\
    Amazon (az)   & 334K  & 0.9M  & 549 \\
    YouTube (yo)    & 1.1M  & 3.0M  & 28754 \\
    Patent (pt)    & 3.8M  & 16.5M & 793 \\
    LiveJournal (lj)    & 4.0M  & 34.7M & 14815 \\
    \hline
    \hline
    EmailEuCore (ee)    & 1K    & 332K  & 9782 \\
    wikitalk (wt)  & 1.1M  & 7.8M  & 264905 \\
    StackOverflow (st)   & 2.6M  & 63.5M & 101663 \\
    \hline
    \end{tabular}%
\label{tab:datasets}
\end{table}%

\noindent
\textbf{\textit{Compared Systems.}} We compare our system against five state-of-the-art systems: STMatch (\textbf{STM})~\cite{wei2022stmatch}, RapidMatch (\textbf{RM})~\cite{sun2020rapidmatch}, DecoMine (\textbf{DM})~\cite{chen2022decomine}, G2Miner (\textbf{GM})~\cite{chen2022efficient},  and Everest (\textbf{EV})~\cite{yuan2023everest}. 
These systems were chosen for their diverse algorithm and optimization supports. 
GM and STM implement the vertex-extension backtracking algorithm for general subgraph listing and motif counting tasks.
DM employs a pattern-decomposition-based algorithm for subgraph counting. 
EV implements an edge-extension backtracking algorithm for temporal subgraph listing. 
RM employs a join-based algorithm for labeled subgraph listing. 
GM, STM, and EV are GPU-based systems, while DM and RM only run on CPU. 

To demonstrate Matcha's flexibility and efficiency, we reimplement the five systems in Matcha and compare performance with their original implementations. 
These reimplementations (referred to as \textbf{mGM}, \textbf{mDM}, \textbf{mSTM}, \textbf{mRM}, and \textbf{mEV}) use the same optimizations as original systems. 
Then, we improve the performance of the reimplementations by enabling various optimizations in our compiler. 
For the two CPU-only systems (DM and RM), we also parallelize the code for GPU execution. 


% The corresponding re-implementations of the baseline system using Matcha are prefixed with 'M-'; for instance, 'M-GM' signifies the re-implementation of GMiner (GM) written in Matcha. The rightmost column of Table~\ref{tab:baseline} shows the GPU programs generated by Matcha for the corresponding methodology, with all optimizations applied. For example, 'M-btv-pd' stands for the subgraph matching program using the backtracking method with vertex extension and pattern decomposition, enabling all the applicable optimizations listed in Table~\ref{tab:intro}. 




% Each baseline system in Table~\ref{tab:baseline} implements one or more tasks. For example, GM, DC, STM, and RM are capable of performing SSL, k-MC, and k-CL, but not TSL. Conversely, EV is specifically designed for TSL. Matcha can generate a program for any task using a specific methodology. For example, Matcha can generate M-btv-pd for k-MC, or M-btv-pd for SSL.



% \begin{table}[t]
%   \centering
%   \footnotesize
%   \caption{The classification and abbreviations of the baseline systems and the programs generated by Matcha. Please refer to the text below this table for a detailed explanation.}
%     \begin{tabular}{l|l|l|l}
%     \hline
%     \multicolumn{1}{c|}{\textbf{Methodology}} & \multicolumn{1}{p{7.085em}|}{\textbf{Baseline\newline{}Systems}} & \multicolumn{1}{p{8.165em}|}{\textbf{Baseline systems\newline{}written in Matcha}} & \multicolumn{1}{p{8em}}{\textbf{Programs written \newline{}in Matcha with \newline{}all optimizations}} \bigstrut\\
%     \hline
%     \multicolumn{1}{p{8.335em}|}{\textbf{Backtracking with \newline{}Vertex Extension }} & \multicolumn{1}{p{7.085em}|}{GM (Gminer)\newline{}STM (STMatch)} & \multicolumn{1}{p{8.165em}|}{M-GM\newline{}M-STM} & M-btv \bigstrut\\
%     \hline
%     \multicolumn{1}{p{8.335em}|}{\textbf{Backtracking with \newline{}Vertex Extension \newline{}and Pattern\newline{}Decomposition}} & DC (Decomine) & M-DC  & M-btv-pd \bigstrut\\
%     \hline
%     \multicolumn{1}{p{8.335em}|}{\textbf{Backtracking with \newline{}Edge Extension}} & EV (Everest) & M-EV  & M-bte \bigstrut\\
%     \hline
%     \textbf{Join Based Method} & RM (RapidMatch) & M-RM  & M-join \bigstrut\\
%     \hline
%     \end{tabular}%
%   \label{tab:baseline}%
% \end{table}%

\subsection{Results for Motif Counting}
We use DC and GM for motif counting as they reportedly achieve the best performance among existing systems for the task on CPU and GPU, respectively. 



%Table~\ref{tab:motif1} and Table~\ref{tab:motif2} list the runtimes. The runtimes exclude data loading and preprocessing times, which can be amortized across multiple applications. 

% Table generated by Excel2LaTeX from sheet 'Motif-Counting'
\begin{table}[t]
  \centering
  \footnotesize
  \caption{Execution time of motif counting with vertex-extension algorithm. `ms', `s', and `m' stand for milliseconds, seconds, and minutes.}
    \centering
    \begin{tabular}{c|c||c|c|c|c|c|c}
   & & \textbf{mc} & \textbf{db} & \textbf{az} & \textbf{yo} & \textbf{pt} & \textbf{lj} \bigstrut\\
    \hline\hline
    \multirow{2}[7]{*}{\rotatebox{90}{3-MC}} 
          & \textbf{GM}    & 2.6ms & 1.2ms & 1.0ms & 18ms & 23ms & 142ms \bigstrut[t]\\
          & \textbf{mGM}   & 2.7ms & 1.2ms & 1.1ms & 18ms & 23ms & 141ms       \bigstrut[t]\\
          & \textbf{mGM-o} & 1.7ms & 0.6ms & 0.4ms & 13ms & 16ms & 136ms \bigstrut[b]\\
    \hline
    \multirow{2}[7]{*}{\rotatebox{90}{4-MC}} 
          & \textbf{GM}          & 1.58s & 0.11s & 0.04s & 227s & 1.93s  & 415s \bigstrut[t]\\
           & \textbf{mGM}        & 1.57s & 0.13s & 0.05s & 227s & 1.93s  &  415s \bigstrut[t]\\
          & \textbf{mGM-o}      & 1.02s  & 0.06s & 0.02s & 192s & 1.78s  & 407s \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tab:motif1}
  \end{table}
  
\begin{table}[t]
  \centering
  \footnotesize
  \caption{Execution time of motif counting with a decomposition-based algorithm. } 
    \begin{tabular}{c|c||c|c|c|c|c|c}

 &  & \textbf{mc} & \textbf{db} & \textbf{az} & \textbf{yo} & \textbf{pt} & \textbf{lj} \bigstrut\\
    \hline\hline
    % \multirow{2}[2]{*}{\textit{3-MC}} 
    %       & \textbf{M-DC-CPU}  & 47 & 15 & 19 & 93 & 332 & 2708 \bigstrut[t]\\
    %       & \textbf{M-DC-GPU} & 0.9 & 0.2 & 0.3 & 2 & 11 & 43 \bigstrut[b]\\
    % \hline
    \multirow{2}[2]{*}{\rotatebox{90}{4-MC}}
          & \textbf{mDM-cpu} & 0.39s & 64ms & 43ms & 0.74s & 1.6s  & 33s \bigstrut[t]\\
          & \textbf{mDM-gpu} & 0.03s   & 3ms & 2ms & 0.06s & 0.09s & 2.3s \bigstrut[b]\\
    \hline
    \multirow{2}[2]{*}{\rotatebox{90}{5-MC}}
          & \textbf{mDM-cpu} & 128s & 1.3s & 0.17s & 576s  & 21s   & 212m \bigstrut[t]\\
          & \textbf{mDM-gpu} & 22s & 0.3s & 0.04s & 17s & 3.3s & 26m \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tab:motif2}
\end{table}%


Table~\ref{tab:motif1} lists the execution time of 3-MC and 4-MC with the vertex-extension algorithm of GM running on GPU. 
The results show that our reimplementation achieves almost the same performance as the original GM system, validating the efficiency of our generated code. 
We further optimize the baseline reimplementation by using a group of 8 threads to execute each iteration of the outermost loop. 
We also enable work-stealing among the thread groups. (The original GM system uses warps for parallel execution without any work-stealing.)
With the optimizations, our generated code (mGM-o) achieves 1.1x to 2.6x speedups ({with an average of 1.5x}) against the original GM.  




Table~\ref{tab:motif2} lists the execution time of 4-MC and 5-MC with the pattern-decomposition algorithm of DM. 
Since DM is not open-sourced, we cannot directly compare performance with their original implementation. 
The execution time of our re-implementation on CPU is close to the numbers reported in their paper, affirming the efficiency of our generated code. 
While the original DM is CPU-only, our system automatically generates GPU code for the algorithm, easily accelerating the execution by 4x to 53x ({with an average of 27x}).  
%The generated GPU code (mDM-gpu) achieves a significant performance advantage over the CPU version.  The observed efficiency of M-btv-pd stems from its automatic deployment of the DC algorithm on GPU architecture. 
%Speedups: 1.1x to 2.3x with an average of 1.56x.

\begin{figure}[t]
   \centering
    \includegraphics[scale=0.33, page=1]{fig/fig_motif1-crop.pdf}
        \vspace{-.5em}
    \caption{Effect of thread-grouping (TG) and work-stealing (WS) on mGM for 3-MC. `ocp', `ut' stand for SM occupancy and thread utilization.}
    \label{fig:motif_ablation}
\end{figure}

\begin{figure}[t]
   \centering
    \subfloat[4-MC]{
        \includegraphics[scale=0.40, page=1]{fig/fig_motif21-crop.pdf}
    }\hfil 
    \subfloat[5-MC]{
        \includegraphics[scale=0.40, page=1]{fig/fig_motif22-crop.pdf}
    }
            \vspace{-.5em}
    \caption{Scalability of multi-threaded mDM on CPU. } 
    \label{fig:motif_ablation2}
\end{figure}


By activating different optimization passes during Matcha compilation, we study the effectiveness of each optimization technique. 
Fig.~\ref{fig:motif_ablation} shows how the performance of mGM is affected by thread-grouping and work-stealing. 
We profile the execution with Nvidia NSight~\cite{nsight} and mark the SM occupancy and thread utilization data in the figure. 
Occupancy is defined as the ratio of active warps on an SM to the maximum number of active warps supported. 
Thread utilization is defined as the ratio of active threads in a warp to the total number of threads in the warp. 
As we can see from the figure, thread-grouping effectively improves thread utilization, bringing 1.1x to 2.5x speedups against the baseline mGM. 
On the other hand, work-stealing has little effect on thread utilization and SM occupancy. 
This is because the nested loop has only two levels for 3-MC, and the baseline mGM already achieves good load balance with dynamic scheduling of the outermost loop. 

For DM, we study how the algorithm scales on a CPU with different numbers of threads.  
Fig.~\ref{fig:motif_ablation2} shows that our generated code achieves near-linear speedups up to 32 threads. When the thread count increases to 64, performance still improves due to the CPU's hyper-threading. 

%Work-stealing has little effect since the dynamic scheduling on many blocks can achieve the load balance well. 
 
 
 % In the next part of this section, we will see that work-stealing only affects the subgraph listing when the pattern size grows large. The virtual warp only affects the graphs with an average node degree far more minor than 32(actual warp size) since it can improve warp utilization when doing set operations. As shown in Fig.~\ref{fig:motif_ablation}(a), we also collected some profiling metrics and marked them on the top of each figure bar. The warp utilization increases as the virtual warp size gets smaller, and occupancy remains high in all cases. The evidence proves the effectiveness of the optimizations. 

 



% We use M-DC as an approximation because DC is not open-sourced. M-DC achieves similar results (96\% to 125\%) as DC in the same environment reported in the Decomine paper. M-btv-pd (CPU) is identical to M-DC.  Speedups: 4.1x to 70.1x with an average of 33.1x.

%----------------------------------------------------------------------------------

\subsection{Results for Subgraph Listing}

\begin{figure}[h]
    \centering
            \vspace{-1em}
    \subfloat[Q1]{
            \includegraphics[scale=0.12, page=1]{fig/pattern-crop.pdf}
    }\hfil
    \subfloat[Q2]{
            \includegraphics[scale=0.12, page=2]{fig/pattern-crop.pdf}
    }\hfil
    \subfloat[Q3]{
        \includegraphics[scale=0.12, page=3]{fig/pattern-crop.pdf}
    }\hfil
    \subfloat[Q4]{
        \includegraphics[scale=0.12, page=4]{fig/pattern-crop.pdf}
    }\hfil
    \subfloat[Q5]{
        \includegraphics[scale=0.12, page=5]{fig/pattern-crop.pdf}
    }\hfil
    \subfloat[Q6]{
        \includegraphics[scale=0.12, page=6]{fig/pattern-crop.pdf}
    }
        \vspace{-.5em}
    \caption{Query patterns for subgraph listing.}
    \label{fig:static_query}
        \vspace{-.5em}
\end{figure}

GM, STM, and RM all support general subgraph listing. 
We test and compare their performance with our Matcha implementation using the query patterns in Fig.~\ref{fig:static_query}. 

%SSL is configured to be edge-induced and evaluated with both labeled and unlabeled queries, where only nodes are labeled, and all edges remain unlabeled. 

% Table generated by Excel2LaTeX from sheet 'SGL'
\begin{table}[t]
  \centering
  \footnotesize 
  \caption{Execution time of unlabeled subgraph listing with vertex extension. `s' stands for seconds. All other numbers are in milliseconds. `$-$' indicates timeout after 4 hours. }
    \begin{tabular}{c|c||c|c|c|c|c|c}
    \textbf{Graph} & & \textbf{Q1} & \textbf{Q2} & \textbf{Q3} & \textbf{Q4} & \textbf{Q5} & \textbf{Q6} \bigstrut\\
    \hline\hline
    \multirow{3}[7]{*}{{az}} 
              & \textbf{STM}         & 12    & 14    & 71    & 80    & 138    & 132  \bigstrut[t]\\
          & \textbf{mSTM}       & 10    & 5.4  & 71    & 16    & 131    & 131 \\
          & \textbf{GM}          & 2.6   & 2.7  & 41    & 8.4  & 132    & 164\\
          & \textbf{mGM}         & 2.5   & 2.7  & 41    & 8.4   &  132    & 164 \\
          & \textbf{mGM-o} & 1.3  & 1.0  & 18 & 3.7  & 131    & 76 \bigstrut[b]\\
    \hline
    \multirow{3}[7]{*}{{db}} 
              & \textbf{STM}         & 312   & 147   & 903   & 368   & 14.6s & 29.4s \bigstrut[t]\\
          & \textbf{mSTM}       & 110   & 39    & 901   & 367   & 14.6s & 28.7s \\
          & \textbf{GM}          & 26    & 12    & 1220  & 388   & 67.0s & 95.6s \\
              & \textbf{mGM}     & 26    & 14    & 1232  & 386   & 67.0s  & 95.6s \\
          & \textbf{mGM-o} & 15 & 5.3  & 457   & 138   & 12.7s & 20.5s \bigstrut[b]\\
    \hline
    \multirow{3}[7]{*}{{mc}} 
              & \textbf{STM}         & 445   & 235   & 122s & 30.3s & $-$     & $-$ \bigstrut[t]\\
          & \textbf{M-STM}       & 449   & 229   & 121s & 30.0s & $-$     & $-$ \\
          & \textbf{GM}          & 769   & 315   & 178s & 35.6s & $-$     & $-$ \\
           & \textbf{mGM}         & 774  & 317   & 178s & 36.6s  & $-$     & $-$ \\
          & \textbf{mGM-o} & 407   & 227   & 121s & 29.3s & $-$     & $-$ \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tab:unlabeled_ssl1}%
\end{table}%

% Table generated by Excel2LaTeX from sheet 'SGL'


\noindent
\textbf{\textit{Performance of Unlabeled Queries.}}
Table~\ref{tab:unlabeled_ssl1} shows the execution time of different systems for listing unlabeled subgraphs of the query patterns. 
In all test cases, our re-implementation of STM (mSTM) either matches or surpasses the performance of the original STM system. 
This is because the original STM needs to maintain a stack data structure to simulate the recursive execution of the backtracking algorithm, while Matcha directly translates the algorithm into a nested loop. 
The performance advantage of mSTM diminishes with large query patterns because the overhead of maintaining the stack data structure becomes small compared to the computation itself. 

GM performs especially well on small queries but is slower than STM for larger queries. 
This is because GM launches many more thread-blocks (7000+) than STM (82) and achieves better GPU occupancy for small tasks, while STM achieves better load balance for larger tasks due to its work-stealing technique. 
Our re-implementation of GM (mGM) achieves almost the same performance as the original GM. 


\begin{figure}[t]
   \centering
        \includegraphics[scale=0.33, page=1]{fig/fig_ssl1-crop.pdf}
                \vspace{-.5em}
    \caption{Effect of thread-grouping (TG) and work-stealing (WS) on mGM for subgraph listing on DBLP graph.}
    \label{fig:ssl_ablation}
            \vspace{-.5em}
\end{figure}



To further improve the performance, we apply thread-grouping and work-stealing to mGM. 
The optimized code (mGM-o) brings the best of both STM and GM, achieving up to 7.7x speedups against the original STM and 4.6x speedups against GM. 
Fig.~\ref{fig:ssl_ablation} shows the effectiveness of each optimization. 
As expected, thread-grouping increases thread utilization, leading to 1.5x to 2.8x speedups against mGM. 
The benefit of work-stealing is small for the size-4 queries (Q1 and Q2), which is similar to the results for 3-MC in Fig.~\ref{fig:motif_ablation}. 
However,  as the pattern size grows (Q3$\sim$Q6), the benefit becomes more noticeable. 
This performance is reflected by the SM occupancy. 
For Q1 and Q2, occupancy is already high without work-stealing. But for Q3$\sim$Q6, work-stealing significantly increases occupancy. 



% To demonstrate the effectiveness of each optimization, we conducted an ablation study. Using M-GM as the baseline, Fig.~\ref{fig:ssl_ablation} shows the speedup achieved by each optimization step. First, we added the virtual warp, which affects graphs with small average node degrees by improving warp utilization. Next, we introduced work stealing, which significantly affects large queries. On small queries, dynamic scheduling can achieve good load balance across many blocks, so work stealing is ineffective in such a situation. However, dynamic scheduling alone cannot resolve the severe load imbalance caused by large queries.

% Table generated by Excel2LaTeX from sheet 'SGL'
\begin{table}[t]
  \centering
  \footnotesize
  \caption{Execution time (in milliseconds) of labeled subgraph listing with vertex extension. }
    \begin{tabular}{c|c||c|c|c|c|c|c}
    \textbf{Graph} & & \textbf{Q1} & \textbf{Q2} & \textbf{Q3} & \textbf{Q4} & \textbf{Q5} & \textbf{Q6} \bigstrut\\
    \hline\hline
    \multirow{2}[2]{*}{az} 
          & \textbf{STM} & 12    & 12    & 12    & 10    & 9.5  & 6.9 \bigstrut[t]\\
          & \textbf{mGM-o} & 0.4  & 0.4  & 0.9  & 3.3  & 1.0  & 0.6 \bigstrut[b]\\
    \hline
    \multirow{2}[2]{*}{db} 
          & \textbf{STM} & 12    & 12    & 14    & 19    & 61    & 83 \bigstrut[t]\\
          & \textbf{mGM-o} & 1.4  & 1.5  & 7.9  & 8.2  & 59    & 58 \bigstrut[b]\\
    \hline
    \multirow{2}[2]{*}{mc} 
          & \textbf{STM} & 8.5  & 8.4  & 366   & 612   & 1371  & 1197 \bigstrut[t]\\
          & \textbf{mGM-o} & 5.3  & 5.1  & 272   & 383   & 1277  & 1183 \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tab:labeled_ssl2}%
\end{table}%


\begin{table}[t]
  \centering
  \footnotesize
      \vspace{-.5em}
  \caption{Execution time of labeled subgraph listing with a join-based algorithm. `s' stands for seconds. All other numbers are in milliseconds.}
    \begin{tabular}{c|c||c|c|c|c|c|c}
    \textbf{Graph} && \textbf{Q1} & \textbf{Q2} & \textbf{Q3} & \textbf{Q4} & \textbf{Q5} & \textbf{Q6} \bigstrut\\
    \hline\hline
    \multirow{2}[7]{*}{az} 
          & \textbf{RM}           & 60    & 67    & 75    & 95    & 90    & 96 \bigstrut[t]\\
          & \textbf{mRM}  & 12     & 14    & 12    & 18    & 18    & 17 \\
          & \textbf{mRMo-cpu} & 1.3   & 1.6   & 1.6   & 2.9   & 1.6   & 1.6 \\
          & \textbf{mRMo-gpu} & 0.1  & 0.1  & 0.3  & 1.2  & 0.2 & 0.2 \bigstrut[b]\\
    \hline
    \multirow{2}[7]{*}{db} 
          & \textbf{RM}           & 71    & 78    & 205   & 360   & 2262  & 1863 \bigstrut[t]\\
          & \textbf{mRM}  & 13    & 17    & 66    & 130   & 971  & 1388 \\
          & \textbf{mRMo-cpu} & 1.8    & 1.0    & 14    & 16   & 260  & 292 \\
          & \textbf{mRMo-gpu } & 0.6  & 0.5  & 7.8  & 8.3  & 56    & 59 \bigstrut[b]\\
    \hline
    \multirow{2}[7]{*}{mc} 
          & \textbf{RM}           & 165   & 223   & 9688  & 18.1s  & 257s  & 207s \bigstrut[t]\\
          & \textbf{mRM} & 62   & 136   & 7983  & 16.7s  & 239s  & 198s \\
          & \textbf{mRMo-cpu} & 8.5   & 18   & 797  & 1.1s  & 28s  & 28s \\
          & \textbf{mRMo-gpu}      & 5.4  & 4.8   & 267   & 0.33s    & 1.25s    & 1.10s \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tab:labeled_ssl1}%
\end{table}%


\begin{figure}[t]
   \centering
   \subfloat[Multi-threading]{
        \includegraphics[scale=0.33, page=1]{fig/fig_ssl3-crop.pdf}
    }\hfill
    \subfloat[Code motion on DBLP graph]{
        \includegraphics[scale=0.33, page=1]{fig/fig_ssl4-crop.pdf}
    }
            \vspace{-.5em}
    \caption{Effect of code motion and multi-threading on RM for labeled subgraph listing. }
    \label{fig:ssl_ablation2}
            \vspace{-.5em}
\end{figure}

\noindent
\textbf{\textit{Performance of Labeled Queries.}}
Table~\ref{tab:labeled_ssl2} shows the performance of the backtracking algorithm for labeled subgraph listing. 
The queries are generated by randomly assigning four labels to the pattern vertices. 
%The original GM implementation does not support labeled queries, so we only test the performance of our optimized re-implementation (mGM-o). 
Compared to STM, our code (mGM-o) is consistently faster for all queries, achieving an average speedup of 7.1x. 



We also test the performance of the join-based algorithm of RM for the same set of labeled queries. 
The results are listed in Table~\ref{tab:labeled_ssl1}. 
The original RM is a single-threaded CPU implementation. 
We reimplement it in Matcha and apply two optimizations, code motion and multi-threading, to it. 
The generated CPU code (mRMo-cpu) is {on average 29.4x} (up to 60x) faster than the original RM. 
Fig.~\ref{fig:ssl_ablation2} shows how each of the two optimizations affects the performance. 
For Q2, Q5, and Q6, code motion significantly reduces the redundant set operations, achieving up to 6.9x speedup. 
It is not effective for Q1, Q3, and Q4 because the three queries do not have redundant set operations. 
As more threads are used for execution, the program runs faster, but the speedups are small. 
This is because the total workloads in these labeled queries are small. 

We further generate GPU code for RM (with code motion activated). 
The GPU code (mRMo-gpu) runs 1.6x to 16x faster than mRMo-cpu. 
Interestingly, when comparing data from Table~\ref{tab:labeled_ssl2} and Table~\ref{tab:labeled_ssl1}, we note that the performance of mRMo-gpu closely matches that of mGM-o for most tasks. 
This observation casts doubt on the practical advantage of the join-based algorithm over the basic vertex-extension on GPU.


\begin{table}[t]
  \centering
  \footnotesize
  \caption{Execution time (in milliseconds) of labeled subgraph counting with decomposition-based and join-based algorithms.}
    \begin{tabular}{c|c||c|c|c|c|c|c}
    \textbf{Graph} &  & \textbf{Q1} & \textbf{Q2} & \textbf{Q3} & \textbf{Q4} & \textbf{Q5} & \textbf{Q6} \bigstrut\\
    \hline\hline
    \multirow{2}[2]{*}{az} 
          & \textbf{mDM-cpu} & 11    & 11    & 1    & 11    & 11    & 11 \bigstrut[t]\\
          & \textbf{mDM-gpu} & 0.3  & 0.3  & 0.5  & 3.2  & 0.4  & 0.3 \\
          & \textbf{mDM-RM} & 0.1  & 0.1 & 0.1  & 2.9  & 0.3  & 0.4 \\
          
    \hline
    \multirow{2}[2]{*}{db} 
          & \textbf{mDM-cpu} & 16    & 16    & 16    & 18  & 15    & 16 \bigstrut[t]\\
          & \textbf{mDM-gpu} & 0.3  & 0.3  & 1.0    & 8.2   & 0.6  & 0.7 \bigstrut[b]\\
           & \textbf{mDM-RM} & 0.1   & 0.1   & 0.3   & 8.2   & 0.5   & 0.7 \\
    \hline
    \multirow{2}[2]{*}{mc} 
          &\textbf{mDM-cpu} & 12    & 13    & 30  & 1056 & 57   & 14 \bigstrut[t]\\
          & \textbf{mDM-gpu} & 0.4  & 0.3  & 8.4   & 263 & 2.7   & 4.5 \bigstrut[b]\\
           & \textbf{mDM-RM} & 0.1  & 0.1 & 3.3  & 259  & 2.4  & 4.3 \\
    \hline
    \end{tabular}%
  \label{fig:ssl_mix}%
\end{table}%


% \begin{table}[t]
%   \centering
%   \footnotesize
%   \caption{Execution time (milliseconds) of M-join-pd (GPU) on unlabeled SSL.\textcolor{red}{Do not have data yet. combine with table 8...}}
%     \begin{tabular}{c|c|c|c|c|c|c|c}
%     \hline
%     \textit{Graph} & \boldmath{}\textbf{System$\backslash$Query}\unboldmath{} & \textbf{Q1} & \textbf{Q2} & \textbf{Q3} & \textbf{Q4} & \textbf{Q5} & \textbf{Q6} \bigstrut\\
%     \hline
%     \textit{az} & \textbf{M-join-pd} & x     & x     & x     & x     & x     & x \bigstrut\\
%     \hline
%     \textit{db} & \textbf{M-join-pd} & x     & x     & x     & x     & x     & x \bigstrut\\
%     \hline
%     \textit{mc} & \textbf{M-join-pd} & x     & x     & x     & x     & x     & x \bigstrut\\
%     \hline
%     \textit{pt} & \textbf{M-join-pd} & x     & x     & x     & x     & x     & x \bigstrut\\
%     \hline
%     \textit{yt} & \textbf{M-join-pd} & x     & x     & x     & x     & x     & x \bigstrut\\
%     \hline
%     \textit{lj} & \textbf{M-join-pd} & x     & x     & x     & x     & x     & x \bigstrut\\
%     \hline
%     \end{tabular}%
%   \label{tab:addlabel}%
% \end{table}%


\noindent
\textbf{\textit{Performance of Subgraph Counting.}}
In some cases, the user might be only interested in the count of subgraphs without listing them. 
The decomposition-based algorithm in DM is most suitable for this task. 
For each sub-pattern, DM simply uses the basic vertex-extension backtracking algorithm to count the matching subgraphs. 
One potential way to improve the performance is to adopt RM to match the sub-patterns. 
While the idea is hard to implement in the original DM or RM system, the implementation is easy in Matcha. 
Table~\ref{fig:ssl_mix} shows the execution time of labeled subgraph counting with our re-implementation of DM on both CPU and GPU, and the combined algorithm (mDM-RM).  
We can see that Matcha easily accelerates DM by 2.2x to 53x with GPU parallelization. 
The combined algorithm further improves the performance on GPU by 1.8x on average.













% give the results of labeled SSL. For labeled SSL, each optimization method has a similar effect as it does on unlabeled SSL. We also made an ablation study on labeled SSL, the results are shown in Fig.~\ref{fig:ssl_ablation2}.



%----------------------------------------------------------------------------------

\subsection{Results for Clique Counting}

Next, we compare GM and Matcha for 4, 5, 6-CL. 
We select GM as baseline because it accelerates the algorithm with an edge-pruning technique and reportedly achieves the best performance for the task among existing systems. 

\begin{table}[H]
  \centering
  \footnotesize
  \caption{Execution time of clique counting with the backtracking algorithm accelerated by edge pruning. `s' stands for seconds. All other numbers are in milliseconds.}
    \begin{tabular}{c|c||c|c|c|c|c|c}
 &  & \multicolumn{1}{c|}{\textbf{mc}} & \multicolumn{1}{c|}{\textbf{db}} & \multicolumn{1}{c|}{\textbf{az}} & \multicolumn{1}{c|}{\textbf{yo}} & \multicolumn{1}{c|}{\textbf{pt}} & \multicolumn{1}{c}{\textbf{lj}} \bigstrut\\
    \hline\hline
    \multirow{3}[1]{*}{4-CL}
          & \textbf{GM} & 15    & 1.5  & 0.6  & 2.8  & 11    & 271 \bigstrut[t]\\
          & \textbf{mGM-o} & 11    & 0.8  & 0.2  & 1.4  & 8.9  & 271 \bigstrut[b]\\
    \hline
    \multirow{3}[1]{*}{5-CL}
          & \textbf{GM} & 592   & 11    & 0.7  & 5.5  & 13    & 9341 \bigstrut[t]\\
          & \textbf{mGM-o} & 551   & 11    & 0.3  & 4.5  & 10    & 9338 \bigstrut[b]\\
    \hline
    \multirow{3}[1]{*}{6-CL}
          & \textbf{GM} & 22.6s & 235   & 0.7  & 10    & 17    & 466s \bigstrut[t]\\
          & \textbf{mGM-o} & 20.3s & 171   & 0.4  & 8.7  & 14    & 466s \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tab:cl}%
\end{table}%


Table~\ref{tab:cl} shows the execution time of the original GM system and our generated code. 
Our code (mGM-o) is optimized with thread-grouping and work-stealing, achieving {1.1x to 2.6x} speedups {with an average of 1.4x} against the original GM. 
According to our profiling, the speedups are mainly attributed to the improved thread utilization by thread grouping. We omit the profiling data here due to the space limit. 

% Table generated by Excel2LaTeX from sheet 'Clique'


%----------------------------------------------------------------------------------

\subsection{Results for Temporal Subgraph Listing}


We use Matcha to re-implement the edge-extension backtracking algorithm of EV and compare the performance with the original EV system. 

\begin{figure}[H]
    \vspace{-1em}
    \centering
    \subfloat[Q7]{
      \includegraphics[scale=0.15, page=7]{fig/pattern-crop.pdf}
    }\hfil
    \subfloat[Q8]{
      \includegraphics[scale=0.15, page=8]{fig/pattern-crop.pdf}
    }\hfil
    \subfloat[Q9]{
      \includegraphics[scale=0.15, page=9]{fig/pattern-crop.pdf}
    }\hfil
    \subfloat[Q10]{
      \includegraphics[scale=0.15, page=10]{fig/pattern-crop.pdf}
    }
    \vspace{-.5em}
    \caption{Temporal Queries.}
    \label{fig:temporal_query}
\end{figure}


We use the four temporal queries in Fig.~\ref{fig:temporal_query} for performance evaluation. 
The numbers on the edges indicate the matching order. 
We adopt the same setting as in the EV paper~\cite{yuan2023everest} and set the {time constraint $\delta$ to one day (86400 seconds). 

% \textcolor{red}{move to corresponding section? The edges of temporal queries Q7 to Q10 are numbered to indicate the matching sequence, and the time window is set to one day (86400 seconds).}


% There's a class of systems that support temporal subgraph listing, with Everest (EV) being the state-of-the-art system. Generally, TSL follows an edge-induced, unlabeled setting.

Table~\ref{tab:tsl} shows the execution time of different queries with the original EV system and our generated code (mEV). 
Our code achieves almost the same performance as the original EV.  
This is because the original EV implementation already incorporates all the applicable optimizations listed in Table~\ref{tab:intro}. Code motion is not helpful in this case because the edge-extension algorithm does not have any set operation, and symmetry breaking cannot be applied to temporal graphs. 
The results confirm the efficiency of our automatically generated code in comparison to the hand-optimized code. 

\begin{table}[H]
  \centering
  \footnotesize
  \caption{Execution time (in milliseconds) of temporal subgraph listing with edge-extension-based backtracking.}
    \begin{tabular}{c|c||c|c|c|c}
   & & \multicolumn{1}{c|}{\textbf{Q7}} & \multicolumn{1}{c|}{\textbf{Q8}} & \multicolumn{1}{c|}{\textbf{Q9}} & \multicolumn{1}{c}{\textbf{Q10}} \bigstrut\\
    \hline\hline
    \multirow{2}[2]{*}{eu} 
          & \textbf{EV} & 1.8   & 4.8   & 4.6   & 3.8 \bigstrut[t]\\
          & \textbf{mEV} & 1.9   & 5.2   & 4.5   & 4 \bigstrut[b]\\
    \hline
    \multirow{2}[2]{*}{wk} 
          & \textbf{EV} & 11  & 21 & 22  & 20 \bigstrut[t]\\
          & \textbf{mEV} & 11  & 22  & 23  & 19 \bigstrut[b]\\
    \hline
    \multirow{2}[2]{*}{st} 
          & \textbf{EV} & 97  & 190 & 217 & 185 \bigstrut[t]\\
          & \textbf{mEV} & 97  & 185 & 193 & 188 \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tab:tsl}%
\end{table}%


%----------------------------------------------------------------------------------

